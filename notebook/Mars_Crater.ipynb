{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the modules\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset\n",
    "\n",
    "- Load the train data and using all your knowledge try to explore the different statistical properties of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>attr0</th>\n",
       "      <th>attr1</th>\n",
       "      <th>attr2</th>\n",
       "      <th>attr3</th>\n",
       "      <th>attr4</th>\n",
       "      <th>attr5</th>\n",
       "      <th>attr6</th>\n",
       "      <th>attr7</th>\n",
       "      <th>...</th>\n",
       "      <th>attr1080</th>\n",
       "      <th>attr1081</th>\n",
       "      <th>attr1082</th>\n",
       "      <th>attr1083</th>\n",
       "      <th>attr1084</th>\n",
       "      <th>attr1085</th>\n",
       "      <th>attr1086</th>\n",
       "      <th>attr1087</th>\n",
       "      <th>attr1088</th>\n",
       "      <th>attr1089</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2216</td>\n",
       "      <td>2216</td>\n",
       "      <td>-4.374765</td>\n",
       "      <td>13.819856</td>\n",
       "      <td>14.656331</td>\n",
       "      <td>-9.728919</td>\n",
       "      <td>-19.334897</td>\n",
       "      <td>0.344455</td>\n",
       "      <td>11.10572</td>\n",
       "      <td>21.977302</td>\n",
       "      <td>...</td>\n",
       "      <td>89.083581</td>\n",
       "      <td>86.194838</td>\n",
       "      <td>93.162055</td>\n",
       "      <td>100.883355</td>\n",
       "      <td>123.558503</td>\n",
       "      <td>112.831384</td>\n",
       "      <td>100.583377</td>\n",
       "      <td>102.194939</td>\n",
       "      <td>120.306692</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2673</td>\n",
       "      <td>2673</td>\n",
       "      <td>-13.796261</td>\n",
       "      <td>-4.647589</td>\n",
       "      <td>21.676617</td>\n",
       "      <td>-0.122074</td>\n",
       "      <td>11.228644</td>\n",
       "      <td>-8.806895</td>\n",
       "      <td>-9.16119</td>\n",
       "      <td>18.025709</td>\n",
       "      <td>...</td>\n",
       "      <td>100.750899</td>\n",
       "      <td>83.373142</td>\n",
       "      <td>76.902208</td>\n",
       "      <td>72.182997</td>\n",
       "      <td>102.843819</td>\n",
       "      <td>93.118477</td>\n",
       "      <td>80.338570</td>\n",
       "      <td>80.196648</td>\n",
       "      <td>93.995657</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5603</td>\n",
       "      <td>5603</td>\n",
       "      <td>-2.115400</td>\n",
       "      <td>-3.332400</td>\n",
       "      <td>-6.640000</td>\n",
       "      <td>-13.825000</td>\n",
       "      <td>4.123200</td>\n",
       "      <td>27.365000</td>\n",
       "      <td>6.70020</td>\n",
       "      <td>3.783000</td>\n",
       "      <td>...</td>\n",
       "      <td>52.917000</td>\n",
       "      <td>34.799000</td>\n",
       "      <td>42.562000</td>\n",
       "      <td>51.161000</td>\n",
       "      <td>77.139000</td>\n",
       "      <td>73.367000</td>\n",
       "      <td>50.733000</td>\n",
       "      <td>39.949000</td>\n",
       "      <td>60.731000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6401</td>\n",
       "      <td>6401</td>\n",
       "      <td>-25.531000</td>\n",
       "      <td>66.699000</td>\n",
       "      <td>-13.025000</td>\n",
       "      <td>-31.198000</td>\n",
       "      <td>12.016000</td>\n",
       "      <td>19.365000</td>\n",
       "      <td>5.04510</td>\n",
       "      <td>20.418000</td>\n",
       "      <td>...</td>\n",
       "      <td>49.488000</td>\n",
       "      <td>71.633000</td>\n",
       "      <td>66.757000</td>\n",
       "      <td>69.213000</td>\n",
       "      <td>97.606000</td>\n",
       "      <td>81.416000</td>\n",
       "      <td>53.808000</td>\n",
       "      <td>41.489000</td>\n",
       "      <td>71.825000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6043</td>\n",
       "      <td>6043</td>\n",
       "      <td>18.993000</td>\n",
       "      <td>-5.620000</td>\n",
       "      <td>-9.964900</td>\n",
       "      <td>3.307200</td>\n",
       "      <td>0.999760</td>\n",
       "      <td>-10.920000</td>\n",
       "      <td>-11.39200</td>\n",
       "      <td>3.918500</td>\n",
       "      <td>...</td>\n",
       "      <td>84.508000</td>\n",
       "      <td>89.976000</td>\n",
       "      <td>61.169000</td>\n",
       "      <td>33.132000</td>\n",
       "      <td>58.043000</td>\n",
       "      <td>54.522000</td>\n",
       "      <td>80.941000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>80.615000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1092 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Id  Unnamed: 0      attr0      attr1      attr2      attr3      attr4  \\\n",
       "0  2216        2216  -4.374765  13.819856  14.656331  -9.728919 -19.334897   \n",
       "1  2673        2673 -13.796261  -4.647589  21.676617  -0.122074  11.228644   \n",
       "2  5603        5603  -2.115400  -3.332400  -6.640000 -13.825000   4.123200   \n",
       "3  6401        6401 -25.531000  66.699000 -13.025000 -31.198000  12.016000   \n",
       "4  6043        6043  18.993000  -5.620000  -9.964900   3.307200   0.999760   \n",
       "\n",
       "       attr5     attr6      attr7  ...    attr1080   attr1081   attr1082  \\\n",
       "0   0.344455  11.10572  21.977302  ...   89.083581  86.194838  93.162055   \n",
       "1  -8.806895  -9.16119  18.025709  ...  100.750899  83.373142  76.902208   \n",
       "2  27.365000   6.70020   3.783000  ...   52.917000  34.799000  42.562000   \n",
       "3  19.365000   5.04510  20.418000  ...   49.488000  71.633000  66.757000   \n",
       "4 -10.920000 -11.39200   3.918500  ...   84.508000  89.976000  61.169000   \n",
       "\n",
       "     attr1083    attr1084    attr1085    attr1086    attr1087    attr1088  \\\n",
       "0  100.883355  123.558503  112.831384  100.583377  102.194939  120.306692   \n",
       "1   72.182997  102.843819   93.118477   80.338570   80.196648   93.995657   \n",
       "2   51.161000   77.139000   73.367000   50.733000   39.949000   60.731000   \n",
       "3   69.213000   97.606000   81.416000   53.808000   41.489000   71.825000   \n",
       "4   33.132000   58.043000   54.522000   80.941000   53.000000   80.615000   \n",
       "\n",
       "   attr1089  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         1  \n",
       "\n",
       "[5 rows x 1092 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code starts here\n",
    "\n",
    "train = pd.read_csv('../data/train.csv')\n",
    "train.head()\n",
    "\n",
    "# Code ends here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop(['Id','Unnamed: 0','attr1089'],axis = 1)\n",
    "y = train['attr1089'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the data\n",
    "\n",
    "- Check the distribution of the target variable. Is the data imbalanced?\n",
    "- Clean the data, apply some data preprocessing and engineering techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    3080\n",
      "0    2812\n",
      "Name: attr1089, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Code starts here\n",
    "#Storing value counts of target variable in 'fully_paid'\n",
    "crater_count = y.value_counts()\n",
    "print(y.value_counts())\n",
    "\n",
    "#Plotting bar plot\n",
    "plt.bar(crater_count.index, crater_count, tick_label = [1,0])\n",
    "plt.show()\n",
    "\n",
    "# Standardize the data\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X)\n",
    "X = scaler.transform(X)\n",
    "\n",
    "\n",
    "# Code ends here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model building\n",
    "\n",
    "- Split the data into train and test.\n",
    "- Now let's come to the actual task, predict the values of `attr1089` after building a Machine learning model.\n",
    "- Try improving upon the `roc_auc_score` ([ROC-AUC Score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html#sklearn.metrics.roc_auc_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8260211041050057\n"
     ]
    }
   ],
   "source": [
    "# Code Starts here\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)\n",
    "\n",
    "# Initialize the logistic regression\n",
    "lr = LogisticRegression()\n",
    "\n",
    "# Fit the model \n",
    "lr.fit(X_train,y_train)\n",
    "\n",
    "# Store the predicted values of test data\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "# roc score\n",
    "roc_score = roc_auc_score(y_pred,y_test)\n",
    "print(roc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8666157372039724\n"
     ]
    }
   ],
   "source": [
    "# Can we improve our model's performance with Decision Tree algorithm?\n",
    "\n",
    "# Initialize decision tree\n",
    "dt = DecisionTreeClassifier(random_state = 4)\n",
    "\n",
    "# Fit the model on train data\n",
    "dt.fit(X_train,y_train)\n",
    "\n",
    "# accuracy\n",
    "accuracy = dt.score(X_test,y_test)\n",
    "\n",
    "# Predicted values for test data\n",
    "y_pred = dt.predict(X_test)\n",
    "\n",
    "# ROC score\n",
    "roc_score = roc_auc_score(y_test,y_pred)\n",
    "print(roc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.920244461420932\n"
     ]
    }
   ],
   "source": [
    "# Can we improve our model's performance with Random forrest algorithm?\n",
    "\n",
    "# Initialize RandomForrest model to variable rfc\n",
    "rfc = RandomForestClassifier(random_state=4)\n",
    "\n",
    "# Fit the model\n",
    "rfc.fit(X_train,y_train)\n",
    "\n",
    "# Store the predicted values of test data\n",
    "y_pred = rfc.predict(X_test)\n",
    "\n",
    "# accuracy\n",
    "accuracy = rfc.score(X_test,y_test)\n",
    "\n",
    "# roc score\n",
    "roc_score = roc_auc_score(y_test,y_pred)\n",
    "print(roc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8359728506787331\n",
      "0.8339190221543163\n"
     ]
    }
   ],
   "source": [
    "# Bagginng or Bootstrap aggregation\n",
    "\n",
    "# Initialize Bagging Classifier\n",
    "bagging_clf = BaggingClassifier(DecisionTreeClassifier(), random_state=0,n_estimators=100,max_samples=100)\n",
    "\n",
    "# Fit the model on training data\n",
    "bagging_clf.fit(X_train,y_train)\n",
    "\n",
    "# Predicted values of X_test\n",
    "y_pred = bagging_clf.predict(X_test)\n",
    "\n",
    "# accuracy \n",
    "print(bagging_clf.score(X_test,y_test))\n",
    "\n",
    "# roc_score\n",
    "score_bagging = roc_auc_score(y_test,y_pred)\n",
    "print(score_bagging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9078054298642534\n"
     ]
    }
   ],
   "source": [
    "# Voting Classifier\n",
    "\n",
    "# Various models\n",
    "clf_1 = LogisticRegression()\n",
    "clf_2 = DecisionTreeClassifier(random_state=4)\n",
    "clf_3 = RandomForestClassifier(random_state=4)\n",
    "\n",
    "model_list = [('lr',clf_1),('DT',clf_2),('RF',clf_3)]\n",
    "\n",
    "# Code starts here\n",
    "# Initialize voting classifier\n",
    "voting_clf_hard = VotingClassifier(estimators=model_list,voting='hard')\n",
    "\n",
    "# Fit the model on training data\n",
    "voting_clf_hard.fit(X_train,y_train)\n",
    "\n",
    "# accuracy\n",
    "hard_voting_score = voting_clf_hard.score(X_test,y_test)\n",
    "print(hard_voting_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction on the test data and creating the sample submission file.\n",
    "\n",
    "- Load the test data and store the `Id` column in a separate variable.\n",
    "- Perform the same operations on the test data that you have performed on the train data.\n",
    "- Create the submission file as a `csv` file consisting of the `Id` column from the test data and your prediction as the second column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code Starts here\n",
    "\n",
    "test = pd.read_csv('../data/test.csv')\n",
    "\n",
    "id_ = test['Id'].copy()\n",
    "\n",
    "test = test.drop(['Id','Unnamed: 0'],1)\n",
    "\n",
    "res = rfc.predict(test)\n",
    "res\n",
    "\n",
    "# sample = pd.read_csv('sample_submission.csv')\n",
    "\n",
    "# sample['Id'] = id_\n",
    "# sample['attr1089'] = res\n",
    "\n",
    "# submission = sample.to_csv('submission.csv', index = False)\n",
    "# Code ends here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
